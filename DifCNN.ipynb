{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74184f27-924a-42e0-881b-9d3dd321c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import cv2\n",
    "\n",
    "def dm3_to_8bit_nparray(file_path):\n",
    "    # load the dm3 file and returns an 8bit np.array\n",
    "    file_path = str(file_path)\n",
    "    data = hs.load(file_path)\n",
    "\n",
    "    data_arr = np.array(data.data)\n",
    "    if data_arr.shape [0] < 1300 or data_arr.shape [1] < 1300:\n",
    "        data_arr = data_arr.astype(np.uint16)\n",
    "    data_8bit = (data_arr/data_arr.max())*255\n",
    "    data_8bit = np.uint8(data_8bit)\n",
    "\n",
    "    return data_8bit\n",
    "\n",
    "def opposite_angle(angle):\n",
    "    #return the opposite angle of the variable angle in range [0:2pi], both input and output in radians\n",
    "\n",
    "    op_angle = angle+np.pi\n",
    "    return np.mod(op_angle, 2*np.pi)\n",
    "\n",
    "def get_centered_crop_img(image, center):\n",
    "    # crops the image to biggest area possible so its get centered on center\n",
    "    c_x = round(center[0])\n",
    "    c_y = round(center[1])\n",
    "\n",
    "    x_lenth = image.shape[0]\n",
    "    y_lenth = image.shape[1]\n",
    "\n",
    "    radius = min(c_x, c_y, abs(x_lenth-c_x), abs(y_lenth-c_y))-1\n",
    "\n",
    "    return image[c_y-radius:c_y+radius, c_x-radius:c_x+radius]\n",
    "\n",
    "def get_polar_image(img, rad_percent='Nan'):\n",
    "    # transformates rectangular coordinates to polar, img needs to be centered in center\n",
    "    if rad_percent == 'Nan':\n",
    "        rad_percent = (0.06, 0.7)\n",
    "    elif rad_percent == 'Full':\n",
    "        rad_percent = (0,1)\n",
    "    value = np.sqrt(((img.shape[0]/2.0)**2.0)+((img.shape[1]/2.0)**2.0))\n",
    "\n",
    "    polar_image = cv2.linearPolar(img,(img.shape[0]/2, img.shape[1]/2), value, cv2.WARP_FILL_OUTLIERS)\n",
    "    polar_image = polar_image.astype(np.uint8)\n",
    "\n",
    "    return polar_image[:,round(rad_percent[0]*polar_image.shape[1]):round(rad_percent[1]*polar_image.shape[1])]\n",
    "\n",
    "def axial_sections(pol_img, direc_angle, semi_range, biaxial=True):\n",
    "    '''\n",
    "    returns the values of a polar image at the interval\n",
    "    [direc_angle-semi_range, direc_angle+semi_range] and [direc_angle+np.pi-semi_range, direc_angle+np.pi+semi_range]\n",
    "    '''    \n",
    "    l = pol_img.shape[0]\n",
    "    theta = np.arange(0, 2*np.pi, 2*np.pi/l)\n",
    "\n",
    "    direc_midle_ind = np.argmin(np.abs(theta-direc_angle))\n",
    "    cntr_midle_ind = int(np.mod(direc_midle_ind+l/2, l))\n",
    "\n",
    "    mns_dirct_bound = np.mod(direc_midle_ind-semi_range, l)\n",
    "    pls_dirct_bound = np.mod(direc_midle_ind+semi_range, l)\n",
    "\n",
    "    mns_cntr_bound = np.mod(cntr_midle_ind-semi_range, l)\n",
    "    pls_cntr_bound = np.mod(cntr_midle_ind+semi_range, l)\n",
    "\n",
    "    if mns_dirct_bound > pls_dirct_bound:\n",
    "        dirct_section = np.append(pol_img[mns_dirct_bound:], pol_img[:pls_dirct_bound], axis=0)\n",
    "        cntr_section = pol_img[mns_cntr_bound:pls_cntr_bound]\n",
    "\n",
    "    elif mns_cntr_bound > pls_cntr_bound:\n",
    "        dirct_section = pol_img[mns_dirct_bound:pls_dirct_bound]\n",
    "        cntr_section = np.append(pol_img[mns_cntr_bound:], pol_img[:pls_cntr_bound], axis=0)\n",
    "\n",
    "    else:\n",
    "        dirct_section = pol_img[mns_dirct_bound:pls_dirct_bound]\n",
    "        cntr_section = pol_img[mns_cntr_bound:pls_cntr_bound]\n",
    "    if biaxial:\n",
    "        return (dirct_section, cntr_section)\n",
    "    else:\n",
    "        return dirct_section\n",
    "\n",
    "def get_rad_pers(angles, pol_img, semi_range='Full', biaxial=True):\n",
    "    #semi_range \\in [1, Full=90]\n",
    "    rad_pers = []\n",
    "    if semi_range == 'Full':\n",
    "        l = pol_img.shape[0]\n",
    "        theta = np.arange(0, 2*np.pi, 2*np.pi/l)\n",
    "        semi_range = round(theta.shape[0]/(round(angles.shape[0]*4)))\n",
    "\n",
    "    for angle in angles:\n",
    "        rad_direct = np.sum(axial_sections(pol_img, angle, semi_range)[0], axis=0)/(2*semi_range)\n",
    "        rad_cntr = np.sum(axial_sections(pol_img, angle, semi_range)[1], axis=0)/(2*semi_range)\n",
    "\n",
    "        if biaxial:\n",
    "            rad_pers.append((rad_direct, rad_cntr))\n",
    "        else:\n",
    "            rad_pers.append(rad_direct)\n",
    "    return np.array(rad_pers)\n",
    "\n",
    "def get_integral_diff(rad_pers, rad_range='Nan'):\n",
    "    # returns the normalized sqrd value of the area between the curves rad_per[0] and rad_per[1]\n",
    "    integrals = []\n",
    "    \n",
    "    for rad_per in rad_pers:\n",
    "        rad_direct = rad_per[0]\n",
    "        rad_cntr = rad_per[1]\n",
    "\n",
    "        rad_diff = (rad_direct-rad_cntr)**2\n",
    "        if rad_range == 'Nan':\n",
    "            integral = np.trapz(rad_diff[round(rad_diff.shape[0]*0.2):round(rad_diff.shape[0]*0.6)])\n",
    "            integrals.append(integral/rad_diff[round(rad_diff.shape[0]*0.15):round(rad_diff.shape[0]*0.6)].shape[0])\n",
    "        elif rad_range == 'Full':\n",
    "            integral = np.trapz(rad_diff)\n",
    "            integrals.append(integral/rad_diff.shape[0])\n",
    "        else:\n",
    "            integral = np.trapz(rad_diff[round(rad_diff.shape[0]*rad_range[0]):round(rad_diff.shape[0]*rad_range[1])])\n",
    "            integrals.append(integral/rad_diff[round(rad_diff.shape[0]*rad_range[0]):round(rad_diff.shape[0]*rad_range[1])].shape[0])\n",
    "    \n",
    "    return np.array(integrals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907b6a6-fca2-4a24-b1d7-c6733bd07017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "# Define a function to oversample the dataset\n",
    "def oversample_data(images, coordinates, filenames, desired_size):\n",
    "    current_size = len(images)\n",
    "    if current_size >= desired_size:\n",
    "        return images, coordinates, filenames\n",
    "\n",
    "    # Calculate how many more samples are needed\n",
    "    additional_samples_needed = desired_size - current_size\n",
    "\n",
    "    # Randomly duplicate samples\n",
    "    additional_images = []\n",
    "    additional_coordinates = []\n",
    "    additional_filenames = []\n",
    "    for _ in range(additional_samples_needed):\n",
    "        index = random.randint(0, current_size - 1)\n",
    "        additional_images.append(images[index])\n",
    "        additional_coordinates.append(coordinates[index])\n",
    "        additional_filenames.append(filenames[index])\n",
    "\n",
    "    # Append the additional samples\n",
    "    oversampled_images = np.concatenate((images, additional_images), axis=0)\n",
    "    oversampled_coordinates = np.concatenate((coordinates, additional_coordinates), axis=0)\n",
    "    oversampled_filenames = np.concatenate((filenames, additional_filenames), axis=0)\n",
    "    \n",
    "    return oversampled_images, oversampled_coordinates, oversampled_filenames\n",
    "\n",
    "image_dir = 'imagens centro'\n",
    "\n",
    "# Load images and coordinates\n",
    "images = []\n",
    "coordinates = []\n",
    "filenames = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    img_path = os.path.join(image_dir, row['Arquivo'])\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"File {img_path} does not exist\")\n",
    "        continue\n",
    "    try:\n",
    "        # Load the dm3 file using hyperspy\n",
    "        dm3_data = hs.load(img_path)\n",
    "        img = dm3_data.data\n",
    "        \n",
    "        # Check if the image is grayscale and convert to RGB if necessary\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        \n",
    "        # Append the processed image, coordinates, and filename\n",
    "        images.append(img_to_array(img))\n",
    "        coordinates.append([row['x'], row['y']])\n",
    "        filenames.append(row['Arquivo'])\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {img_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not images:\n",
    "    raise ValueError(\"No images were loaded. Check the image directory and file paths.\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images, dtype=\"float\") / 255.0\n",
    "coordinates = np.array(coordinates, dtype=\"float\")\n",
    "filenames = np.array(filenames)\n",
    "\n",
    "# Oversample the data\n",
    "desired_size = 10000  # Set desired size of the dataset\n",
    "oversampled_images, oversampled_coordinates, oversampled_filenames = oversample_data(images, coordinates, filenames, desired_size)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "(trainX, testX, trainY, testY, trainFilenames, testFilenames) = train_test_split(\n",
    "    oversampled_images, oversampled_coordinates, oversampled_filenames, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# Load the pre-trained ResNet50 model + higher level layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "top_model = base_model.output\n",
    "top_model = GlobalAveragePooling2D()(top_model)\n",
    "top_model = Dense(128, activation='relu')(top_model)\n",
    "top_model = Dropout(0.1)(top_model)\n",
    "top_model = Dense(32, activation='relu')(top_model)\n",
    "top_model = Dense(2, activation='linear')(top_model)  # Output layer with 2 units (x, y coordinates)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=top_model)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(aug.flow(trainX, trainY, batch_size=32),\n",
    "                    validation_data=(testX, testY),\n",
    "                    epochs=50,\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(testX, testY)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(testX)\n",
    "int_predictions = np.round(predictions).astype(int)  # Round and convert to integer\n",
    "\n",
    "# Display the first 5 predictions and their corresponding filenames\n",
    "for i in range(5):  # Display the first 5 predictions\n",
    "    print(f\"File: {testFilenames[i]}\")\n",
    "    print(f\"Predicted: {2 * int_predictions[i]}, Actual: {testY[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd8a5d-4174-45df-9a81-9403b4a9e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(testX)\n",
    "int_predictions = np.round(predictions).astype(int)  # Round and convert to integer\n",
    "\n",
    "# Display the first 5 predictions and their corresponding filenames\n",
    "for i in range(5):  # Display the first 5 predictions\n",
    "    print(f\"File: {testFilenames[i]}\")\n",
    "    print(f\"Predicted: {int_predictions[i]}, Actual: {testY[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774e0f9-0795-4a46-bba4-bec3aa7ad360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperspy.api as hs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "a = hs.load('imagens centro/285 mm 64f 1s  Fe3O4.dm3')\n",
    "image_data = a.data\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(testX)\n",
    "int_predictions = np.round(predictions).astype(int)  # Round and convert to integer\n",
    "\n",
    "# Display the first 5 predictions and their corresponding filenames\n",
    "for i in range(5):\n",
    "    # Plot the image\n",
    "    plt.imshow(image_data, cmap='gray')\n",
    "\n",
    "    # Add a marker at the specified coordinates (adjust coordinates as needed)\n",
    "    plt.scatter(int_predictions[i][0], int_predictions[i][1], color='red', marker='o', s=10)\n",
    "    plt.scatter(testY[i][0], testY[i][1], color='blue', marker='o', s=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.title(f\"File: {testFilenames[i]} | Predicted: {int_predictions[i]}, Actual: {testY[i]}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
